{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled深層学習.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgFtn+Aq+IUXcn3pt6+X3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kawakami18/e2021.0214/blob/main/Untitled%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bly2G39AIHgL"
      },
      "source": [
        "#**深層学習day1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH7W5oQJt2RR"
      },
      "source": [
        "# Section1:入力層〜中間層"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLXkOLPQj8dx"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvAN1oABukNp"
      },
      "source": [
        "入力層はニューラルネットワークに何かしらの数字の集まりをxに入力する層になる。入力を受け取る部分をノードという。入力のx中間層の総入力のuに渡す際に、各々のxをどの程度の割合で使用するかに応じて重みのWを掛け中間層の総入力のuに渡す。各々のxの全体に対して使用の割合を調整するときは、バイアスのｂを加える。関数で表現するならば重みのｗは関数の傾きの度合いを調整し、バイアスのｂは関数の切片の度合いを調整させるため、関数は平行移動する。u=W(傾き)x+b(切片)。中間層が1つの時はニューラルネットワークと呼ばれるが、中間層が2層以上になるとディープニューラルネットワークになる。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJdnxjhWhmmG"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX7JvEvCinz6",
        "outputId": "c998a069-076f-4fc8-e96f-9d40750355ba"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(u):\n",
        "    return np.maximum(0, u)\n",
        "\n",
        "W = np.array([[0, 1], [0, 2]])\n",
        "\n",
        "print(\"重み\", W)\n",
        "\n",
        "b = 0.5\n",
        "\n",
        "print(\"入力\", b)\n",
        "\n",
        "x = np.array([2, 3])\n",
        "\n",
        "print(\"入力\", x)\n",
        "\n",
        "u = np.dot(x, W) + b\n",
        "\n",
        "print(\"総入力\", u)\n",
        "\n",
        "z = relu(u)\n",
        "\n",
        "print(\"中間層出力\", z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "重み [[0 1]\n",
            " [0 2]]\n",
            "入力 0.5\n",
            "入力 [2 3]\n",
            "総入力 [0.5 8.5]\n",
            "中間層出力 [0.5 8.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nii0WTQLrunC"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxuJdK-O959c"
      },
      "source": [
        "入力層\n",
        "\n",
        "$x_1=10$ 身長\n",
        "\n",
        "$x_2=300$ 体重\n",
        "\n",
        "$x_3=300$ ひげの本数\n",
        "\n",
        "$x_4=15$ 毛の平均長\n",
        "\n",
        "$x_5=50$ 耳の大きさ\n",
        "\n",
        "$x_6=1.8$ 眉間/目鼻距離比\n",
        "\n",
        "$x7=20$ 足の長さ\n",
        "\n",
        "これら$x_1〜x_7$が入力になりWとｂで度合いを調整し次の層へ情報を伝播する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0YNyYew1LFK"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWX5A4Mm1aXY"
      },
      "source": [
        "・ニューラルネットワークの入力層から中間層を中継し出力層へデータが流れることを順伝播という。特に順伝播の処理だけを行うネットワークをフィードフォワードニューラルネットワークと呼ぶ。\n",
        "\n",
        "・入力層は第0層になるが、たんに信号を出力するだけなので、層にカウントされないのでゼロ層となる。そしてPythonで実装する際に入力層を0にしたほうが都合がよい。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWpSs1Sz5HGu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41irqb8n5NAb"
      },
      "source": [
        "# Section2:活性化関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx0jukoZ5U3a"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDbbxnSe6rX3"
      },
      "source": [
        "活性化関数を導入することでニューラルネットワークで行える処理の幅が広がる。関数は非線形になる。非線形な関数は加法性と斉次性を満たさない。中間層用の活性化関数はReLU関数、シグモイド関数、ステップ関数などがある。出力層用の活性化関数はソフトマックス関数、恒等関数、シグモイド関数などがある。\n",
        "\n",
        "活性化関数は入力された値がWとｂで重みの度合いを調整したあとに、活性化関数を通すことでどの値を特に使うかを決定して次の層に送る。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfksBarKWpdG"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48U2ym9IVT_y",
        "outputId": "3b45f027-7396-4e4c-e28b-f50f6fb57940"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def init_network():\n",
        "  network = {}\n",
        "  network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "  network['b1'] = np.array([0.1, 0.2, 0.3])\n",
        "  network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "  network['b2'] = np.array([0.1, 0.2])\n",
        "  network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "  network['b3'] = np.array([0.1, 0.2])\n",
        "  \n",
        "  return network\n",
        "\n",
        "def forword(network, x):\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  z2 = sigmoid(a2)\n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y = identity_function(a3)\n",
        "  \n",
        "  return y\n",
        "\n",
        "def identity_function(x): #恒等関数\n",
        "  return x\n",
        "\n",
        "def sigmoid(x): #シグモイド関数\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "network = init_network()\n",
        "x = np.array([1.0, 0.5]) \n",
        "y = forword(network, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.31682708 0.69627909]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bvSWTLDXcrE"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "IhGXwVC7X3rq",
        "outputId": "115c0fc9-68de-46db-df76-72e6224b4237"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#線形な関数\n",
        "x = np.arange(0, 10, 0.1)\n",
        "y = x * 2\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "#非線形な関数\n",
        "x = np.arange(-10, 10, 0.1)\n",
        "e = math.e\n",
        "y = 1 / (1 + e**-x)\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRc9X338fdXuxd5lbzJ8gbGeAEbWxAgbGGzIcFu00DM05AFGpqFnvSkaUue9BAOyenzpGnyNDmlIbTZWAohpBA3MRGGkJIFg20wYHnB8i5hLV4lW5Y0y/f5Y67NICRrbI/mzow+r3PGM/fe38x8fefqo6vfvXN/5u6IiEjuKwi7ABERSQ8FuohInlCgi4jkCQW6iEieUKCLiOSJorDeuKKiwqdNmxbW24uI5KR169btc/fK3paFFujTpk1j7dq1Yb29iEhOMrNdfS1Tl4uISJ5QoIuI5AkFuohInlCgi4jkCQW6iEie6DfQzeyHZtZiZhv6WG5m9l0zqzezN8xsYfrLFBGR/qSyh/5jYMlJlt8AzAxudwLfO/OyRETkVPV7Hrq7v2hm007SZBnwkCeuw7vazEaZ2UR335umGkUkj7k7XdE4XZE4ndEY3dE40bgTi8eJxJxY3InGnWjs+HwnEosH98eXx4m74w5xT7ymOzhJ83DiDri/04b3tk9MQzy4tPjxZQD+rrqTHicteff83p9wzezxzK8ela5VeEI6vlhUBexJmm4I5r0n0M3sThJ78UyZMiUNby0iYXJ32jqjtLZ30tLexYGj3bQdi9LWGaHtWCS4j9LeGaGtM8rRrihd0TidkVhwS4T4YBmWwSxxP25EWdYGesrc/UHgQYCamppB8hGK5C53p/HQMXbv72D3gQ52HUjcv33oGK3tXbS2d9EVjff63KICo7ysiBFDihlRVkx5WRGjhw5lSEkhZUUFlBUXUlZ8/L7wxHRxYQHFhUZRQQFFBUZRYeK+sMAoCuYXFhjFhcG8YLqwwCgwMAwzgts78woMMCgww3j3MisAI1gWtIHgNY4/N2D2zkTSbKyPNpmUjkBvBKqTpicH80Qkh0RicerebmND42E2N7WxeW87m5vaOdIVPdGmqMCYPHoIVaOHcOG0MVSWlzKuvJTK4FYxvJQRZcWMGFLEkOLC0IJtsEpHoK8A7jKzx4H3AYfVfy6S/bqjcV7dfZBXdhzglR0HeHX3QTq6YwCUlxUxe8IIPrywilkTypk+dhhTxg5l4sghFBYopLNVv4FuZo8BVwEVZtYAfBUoBnD3B4CVwI1APdABfGqgihWRM9PeGeH5TS2s2tTMi1taae+KYgazxpdz86LJXDh9DAuqR1E1aoj2rnNQKme53NrPcgc+n7aKRCStYnHn9/X7+Pm6BmrrmuiKxqksL+WD50/k6nPH8b7pYxk5tDjsMiUNQrt8rogMrCNdUZ5Ys4cf/XEHew4cY+SQYm6pqeZPLqjigupRFKjrJO8o0EXyTFtnhH9/cTs//sNO2rui1Ewdzd1LZnPtnHGUFhWGXZ4MIAW6SJ7ojMR4ZPUu7n+hnoMdEW48bwKfvnwGF0wZHXZpkiEKdJE88NK2/fzvp95kx76jXD6zgr9bfC7nTR4ZdlmSYQp0kRx2+FiE/7NyE4+v2cOUMUN56PaLuOKcXoeblEFAgS6So9bvOcTnH32VprZO/vLKGfz1NecwpER95IOZAl0kx7g7D720i6//aiPjysv4+WcvZcEAXBdEco8CXSSHdEfj/P3P3+Cp1xq55txxfOuW+YwaWhJ2WZIlFOgiOeJIV5TPPrKO323dxxevO4e7PnC2ziWXd1Ggi+SAfUe6+NSP1rBxbxvf/Mj53FxT3f+TZNBRoItkuf1Huvjo91+i8dAxHrxtEdfMHh92SZKlFOgiWay9M8InfvQKDQeP8ZPbL+LiGWPDLkmyWCpjiopICDojMe74yVo2723ngY8tUphLv7SHLpKF4nHnrx57jTU7D/AvH13AB84dF3ZJkgO0hy6Shf7l+a2s2tjMPR+aw7IFVWGXIzlCgS6SZZ6ta+K7z2/l5kWT+eSl08IuR3KIAl0ki9S3HOGLT7zO+ZNH8rU/madRg+SUKNBFskRnJMZnHllHaVEBD3xsEWXFui6LnBodFBXJEv/06y3Utxzh4TsuYtKoIWGXIzlIe+giWeClbfv54R928PFLpnL5TF3+Vk6PAl0kZO2dEb70s9eZXjGMu284N+xyJIepy0UkZF//5Sb2Hj7Gk5+9lKEl+pGU06c9dJEQvbx9Pz9du4c7rziLhRr7U86QAl0kJNFYnK+uqKNq1BC+cM3MsMuRPKBAFwnJoy/vZnNTO//wwdkaOk7SQoEuEoL9R7r41rNbuOzsCpbMmxB2OZInFOgiIfhm7RY6umPcu3SOvg0qaaNAF8mwzU1t/HTtHj556TTOHlcedjmSRxToIhn2rWffYnhJEXddfXbYpUieUaCLZND6PYdYtbGZT18xg1FDS8IuR/KMAl0kg7717BZGDy3m9sumh12K5KGUAt3MlpjZFjOrN7O7e1k+xcxeMLPXzOwNM7sx/aWK5LaXt+/nd1v38dmrzmJ4qb4RKunXb6CbWSFwP3ADMAe41czm9Gj2D8AT7n4BsBz4t3QXKpLL3J1/fnYL48pL+fgl08IuR/JUKnvoFwH17r7d3buBx4FlPdo4MCJ4PBJ4O30liuS+1dsPsGbnQe66+mxd51wGTCqBXgXsSZpuCOYluxf4mJk1ACuBv+rthczsTjNba2ZrW1tbT6Nckdz0/Re3MXZYCbfUVIddiuSxdB0UvRX4sbtPBm4EHjaz97y2uz/o7jXuXlNZqWs+y+CwuamN325p5ZOXTtPeuQyoVAK9EUjerZgczEt2B/AEgLu/BJQBFekoUCTXPfjidoYUF3LbJVPDLkXyXCqBvgaYaWbTzayExEHPFT3a7AauATCz2SQCXX0qMui9fegYK9a/zfKLqnXeuQy4fgPd3aPAXUAtsInE2Sx1ZnafmS0Nmv0N8Gkzex14DPiku/tAFS2SK370hx04cIfOO5cMSOlkWHdfSeJgZ/K8e5IebwTen97SRHJbW2eE/3x5Nx86fyKTRw8NuxwZBPRNUZEB8vN1DRztjvEXl80IuxQZJBToIgPA3Xlk9S4WVI/ivMkjwy5HBgkFusgAeGn7fra1HuW2i3Vmi2SOAl1kADyyehejhhbzwfMnhl2KDCIKdJE0a27rpLaumVtqqvVFIskoBbpImj32ym5icefP3zcl7FJkkFGgi6RRJBbnsVd2c+U5lUwdOyzscmSQUaCLpNELm1tobuviYzoYKiFQoIuk0ZPrGqgYXsoHZunic5J5CnSRNNl3pIvfbG7hwwurKCrUj5ZknrY6kTT5xfq3icadjyyaHHYpMkgp0EXSwN352do9zJ88knPGl4ddjgxSCnSRNKh7u43NTe3aO5dQKdBF0uDJdQ2UFBawdH7P0RlFMkeBLnKGuqNxfrG+kevmjmfk0OKwy5FBTIEucoZe2NLCwY6IulskdAp0kTO0Yv3bjB1WwuVnaxhdCZcCXeQMtHdGeG5TMx88f6LOPZfQaQsUOQOrNjbTFY2zdP6ksEsRUaCLnIkVr79N1aghLJwyOuxSRBToIqdr/5Eufrd1HzfNn0RBgYVdjogCXeR0rdzQRCzu6m6RrKFAFzlNK9Y3MnPccGZP1Ff9JTso0EVOQ+OhY6zZeZCl8ydhpu4WyQ4KdJHT8MybewG4Sd0tkkUU6CKnobauiXMnlDOtQsPMSfZQoIucotb2LtbuOsj1cyeEXYrIuyjQRU7Rc5uacYfFc8eHXYrIuyjQRU5RbV0Tk0cPYc7EEWGXIvIuCnSRU9DeGeGP9ftZPHeCzm6RrJNSoJvZEjPbYmb1ZnZ3H21uMbONZlZnZv+Z3jJFssMLW1rpjsVZrP5zyUJF/TUws0LgfuA6oAFYY2Yr3H1jUpuZwJeB97v7QTMbN1AFi4Sptq6JscNKWDRV126R7JPKHvpFQL27b3f3buBxYFmPNp8G7nf3gwDu3pLeMkXC1xWN8dvNLVw3ZzyFunaLZKFUAr0K2JM03RDMS3YOcI6Z/cHMVpvZkt5eyMzuNLO1Zra2tbX19CoWCckf6/dztDum7hbJWuk6KFoEzASuAm4F/t3MRvVs5O4PunuNu9dUVlam6a1FMqO2ronhpUVcevbYsEsR6VUqgd4IVCdNTw7mJWsAVrh7xN13AG+RCHiRvBCLO6s2NnPVrEpKiwrDLkekV6kE+hpgpplNN7MSYDmwokebp0nsnWNmFSS6YLansU6RUK3bdZD9R7vV3SJZrd9Ad/cocBdQC2wCnnD3OjO7z8yWBs1qgf1mthF4Afhbd98/UEWLZFptXRMlhQVcNUtdhZK9+j1tEcDdVwIre8y7J+mxA18MbiJ5xd2prWvi/WePpbysOOxyRPqkb4qK9GPj3jYaDh5Td4tkPQW6SD9q65opMLh2ji7GJdlNgS7Sj2frmqiZOoaK4aVhlyJyUgp0kZPYtf8om5vauV6XypUcoEAXOYnauiYA9Z9LTlCgi5xEbV0zcyaOoHrM0LBLEemXAl2kDy3tnby6+6D2ziVnKNBF+rBqYzDU3Dz1n0tuUKCL9KG2rpmpY4cya3x52KWIpESBLtKLts4IL23bp6HmJKco0EV68cLmFiIxZ7FOV5QcokAX6UVtXROV5aVcUK2h5iR3KNBFeuiMxPjtllaumzOeAg01JzlEgS7Sw++37qNDQ81JDlKgi/RQW9dEeVkRl8zQUHOSWxToIkmisTjPbWrm6nPHUVKkHw/JLdpiRZKs2XmQgx0RdbdITlKgiySprWuipKiAK8/RUHOSexToIgF3Z9XGZq6YWcGw0pRGZxTJKgp0kcCGxjYaDx3jenW3SI5SoIsEauuaEkPNzda3QyU3KdBFArV1TVw4bQxjhpWEXYrIaVGgiwDbW4+wteWIzm6RnKZAFyFxqVxAY4dKTlOgi5DobplXNYLJozXUnOQuBboMek2HO1m/5xCL56i7RXKbAl0GvVUbmwBYPE+BLrlNgS6DXm1dM9MrhjFz3PCwSxE5Iwp0GdQOd0RYvX0/188dr6HmJOcp0GVQW7WpmWjcWaLTFSUPKNBlUPv1hr1MGlnGgupRYZcicsZSCnQzW2JmW8ys3szuPkm7PzMzN7Oa9JUoMjDaOyO8+NY+lsybqO4WyQv9BrqZFQL3AzcAc4BbzWxOL+3KgS8AL6e7SJGB8JvNLXTH4txwnrpbJD+ksod+EVDv7tvdvRt4HFjWS7uvAd8AOtNYn8iAeebNJsaVl7JoyuiwSxFJi1QCvQrYkzTdEMw7wcwWAtXu/quTvZCZ3Wlma81sbWtr6ykXK5IuHd1RfvtWC4vnTqCgQN0tkh/O+KComRUA3wb+pr+27v6gu9e4e01lpUaEkfD8z5ZWOiPqbpH8kkqgNwLVSdOTg3nHlQPzgN+a2U7gYmCFDoxKNlu5oYkxw0q4aNqYsEsRSZtUAn0NMNPMpptZCbAcWHF8obsfdvcKd5/m7tOA1cBSd187IBWLnKHOSIzfbGpm8dzxFBXqzF3JH/1uze4eBe4CaoFNwBPuXmdm95nZ0oEuUCTdfrd1H0e7YyyZNzHsUkTSKqWRcN19JbCyx7x7+mh71ZmXJTJwntmwl5FDirn0rLFhlyKSVvp7UwaV7micVRubuXb2eIrV3SJ5Rlu0DCp/3LaP9s4oN+rsFslDCnQZVJ55s4nhpUVcNrMi7FJE0k6BLoNGVzTGr+uauHb2OEqLCsMuRyTtFOgyaLz41j4OH4uwbEFV/41FcpACXQaNFa+/zeihxepukbylQJdBoaM7ynMbm7nxvIk6u0XylrZsGRRWbWzmWCTG0vmTwi5FZMAo0GVQWLH+bSaOLONCXbtF8pgCXfLeoY5uXtzayk3zJ+lSuZLXFOiS957Z0EQk5upukbynQJe89/RrjcyoGMbcSSPCLkVkQCnQJa/t3t/ByzsO8OGFVRoIWvKeAl3y2s9fbcAMPrxwctiliAw4BbrkrXjceXJdA5edXcGkUUPCLkdkwCnQJW+t3rGfxkPH+Mgi7Z3L4KBAl7z15NoGykuLWDxXl8qVwUGBLnmpvTPCyg17+dD8SZQV68qKMjgo0CUvrXxzL52RuLpbZFBRoEteemJtAzMqh7FwyqiwSxHJGAW65J1Ne9tYt+sgyy+s1rnnMqgo0CXvPLJ6FyVFBdy8qDrsUkQySoEueaW9M8LTrzVy0/mTGD2sJOxyRDJKgS555enXGjnaHeO2S6aGXYpIxinQJW+4Ow+v3sV5VSOZP3lk2OWIZJwCXfLGKzsO8FbzEW67eKoOhsqgpECXvPHIy7sZUVbETbruuQxSCnTJC42HjrHyzb3cXFPNkBJ9M1QGJwW65IUf/n4HALdfNj3kSkTCo0CXnHe4I8Jjr+xm6fxJVOkyuTKIpRToZrbEzLaYWb2Z3d3L8i+a2UYze8PMnjcznTMmGfPIy7vo6I5x5xUzwi5FJFT9BrqZFQL3AzcAc4BbzWxOj2avATXufj7wJPBP6S5UpDedkRg/+sNOrjynktkTNWaoDG6p7KFfBNS7+3Z37wYeB5YlN3D3F9y9I5hcDegSd5IRT73WyL4jXfyl9s5FUgr0KmBP0nRDMK8vdwDP9LbAzO40s7Vmtra1tTX1KkV6EY3FefDF7ZxXNZJLzhobdjkioUvrQVEz+xhQA3yzt+Xu/qC717h7TWVlZTrfWgahp15rZMe+o3z+A2fpi0QiQFEKbRqB5MvWTQ7mvYuZXQt8BbjS3bvSU55I77qjcb7z/FbOqxqpIeZEAqnsoa8BZprZdDMrAZYDK5IbmNkFwPeBpe7ekv4yRd7tp2v30HDwGH9z/TnaOxcJ9Bvo7h4F7gJqgU3AE+5eZ2b3mdnSoNk3geHAz8xsvZmt6OPlRM5YZyTGv/5mKxdOG82V56jrTuS4VLpccPeVwMoe8+5JenxtmusS6dPDL+2iua2L7yy/QHvnIkn0TVHJKYc7Inzvf7Zx+cwKLp6hM1tEkinQJaf8v+fe4lBHN3+/5NywSxHJOgp0yRmb9rbx0Es7+V/vm8K8Kg1gIdKTAl1ygrvz1RV1jBxSzJeunxV2OSJZSYEuOeG/39jLKzsO8LeLz2XUUA3+LNIbBbpkvbbOCP/4q03MqxrBRy+s7v8JIoNUSqctioTpvv/eSOuRLh64bRGFBTpNUaQv2kOXrLZqYzNPrmvgc1edxYLqUWGXI5LVFOiStfYf6eLL//UGcyeN4K+unhl2OSJZT10ukpXcna88tYG2Y1Ee/YsFlBRp30OkP/opkaz00Eu7+HVdE1+8/hxmTSgPuxyRnKBAl6zzyo4DfO2XG7l29jjuvFwjEYmkSoEuWWXv4WN87tF1TBkzlG9/dAEFOqtFJGXqQ5es0RmJ8dlHXuVYd4zHPn0xI8qKwy5JJKco0CUrRGJxPv/oq7zecIjv/fkiZo5Xv7nIqVKXi4QuHne+9LPXeX5zC/ctm8eSeRpSTuR0KNAlVO7Ovf9dxy/Wv83fLp7FbRdPDbskkZylLhcJTSzu/MPTG3jsld385RUz+NxVZ4VdkkhOU6BLKDojMb7w+GvU1jXz+Q+cxZeun6Xh5ETOkAJdMu5QRzd3PryOV3Yc4Ks3zeFT758edkkieUGBLhm1fs8hPv/oq7S0d/Kd5QtYtqAq7JJE8oYCXTLC3XnopV18/VcbGVdexpOfuZT5unqiSFop0GXA7TnQwVee3sCLb7Vy9bnj+PYt8zXqkMgAUKDLgInFnR//cSf/XLsFM7j3pjl8/JJp+jq/yABRoEvauTvPbmzmm7VbqG85wgdmVfL1Pz2PqlFDwi5NJK8p0CVt4nHnf95q5bu/2cpruw8xo3IYD3xsIYvnTtApiSIZoECXM9bRHeXp197mB7/fzrbWo0wcWcY3/uw8/mzhZIoK9WVkkUxRoMtpiced1Tv281+vNvLMm3s52h1jXtUIvrN8ATeeN5FiBblIxinQJWVHu6L8cdt+nt/UzHObWth3pIvhpUV86PxJfKRmMjVTR6trRSRECnTp06GObtbsPMianQd4eccBNjQeJhZ3ykuLuHJWJdfPncB1s8czpKQw7FJFBAW6kOgD332gg/qWI2ze287mpjY27W2n8dAxAEoKC1hQPYrPXDmDS2ZUcNH0MRq0WSQLpRToZrYE+A5QCPyHu//fHstLgYeARcB+4KPuvjO9pcqpcneOdEVpbe+ipb2L1uDW0t5Fc1snuw90sGt/B/uOdJ14TmGBcVblMBZNHc2fXzyFRVNGM796FGXF2gsXyXb9BrqZFQL3A9cBDcAaM1vh7huTmt0BHHT3s81sOfAN4KMDUXAucneicScW3KIn7uOJ+1iwzP3EdHcsTmckRmckRlc08bgrEqczGtxHYnRGY3RG4rR3RmjvjNLWGaHtWJT2zghtnVHajkWIxv099RQXGuPKy6geM4Srz61k6thhVI8ZyoyKYcwcP5zSIoW3SC5KZQ/9IqDe3bcDmNnjwDIgOdCXAfcGj58E/tXMzN3fmyZn6Ik1e/j+i9sA8OCf42/i7jhw/F0dx/2d6ZO2ObE8mHti+TvPOb48efr4+7+nDU48DtF4nF4yNS0KC4yyogLKy4oZMaSI8rJiKoaXMKNyGOVlRYwoK2bkkGLGjSilcnhZcF/KyCHF+ramSB5KJdCrgD1J0w3A+/pq4+5RMzsMjAX2JTcyszuBOwGmTJlyWgWPHlbCuRNGQJBHlnjd45OYvTPv+HIMjrd4Z3mPeXai9bvaJObaiXkkv3Yvy0/MM6OwwCgqSNwXmlFYeHy64MT8ogKjIKldUUEBhQVQUlRAWVEhpcWFlBUXUFqUuC8rLqSsuJDSogKdGigi75LRg6Lu/iDwIEBNTc1p7bdeN2c8180Zn9a6RETyQSq7eI1AddL05GBer23MrAgYSeLgqIiIZEgqgb4GmGlm082sBFgOrOjRZgXwieDxR4DfDET/uYiI9K3fLpegT/wuoJbEaYs/dPc6M7sPWOvuK4AfAA+bWT1wgEToi4hIBqXUh+7uK4GVPebdk/S4E7g5vaWJiMip0GkSIiJ5QoEuIpInFOgiInlCgS4ikicsrLMLzawV2HWaT6+gx7dQs0i21qa6To3qOnXZWlu+1TXV3St7WxBaoJ8JM1vr7jVh19GbbK1NdZ0a1XXqsrW2wVSXulxERPKEAl1EJE/kaqA/GHYBJ5GttamuU6O6Tl221jZo6srJPnQREXmvXN1DFxGRHhToIiJ5ImsD3cxuNrM6M4ubWU2PZV82s3oz22Jmi/t4/nQzezlo99Pg0r/prvGnZrY+uO00s/V9tNtpZm8G7damu44+3vNeM2tMqu/GPtotCdZjvZndnYG6vmlmm83sDTN7ysxG9dEuI+usv/+/mZUGn3N9sD1NG6hakt6z2sxeMLONwc/AF3ppc5WZHU76fO/p7bUGqL6TfjaW8N1gnb1hZgszUNOspHWx3szazOyve7TJyDozsx+aWYuZbUiaN8bMVpnZ1uB+dB/P/UTQZquZfaK3Nifl7ll5A2YDs4DfAjVJ8+cArwOlwHRgG1DYy/OfAJYHjx8APjvA9X4LuKePZTuBigyvv3uBL/XTpjBYfzOAkmC9zhnguq4HioLH3wC+EdY6S+X/D3wOeCB4vBz4aQY+u4nAwuBxOfBWL3VdBfwyk9tUqp8NcCPwDIlRGS8GXs5wfYVAE4kv4GR8nQFXAAuBDUnz/gm4O3h8d2/bPTAG2B7cjw4ejz6V987aPXR33+TuW3pZtAx43N273H0HUE9iIOsTLDHo59UkBqwG+AnwJwNVa/B+twCPDdR7DJATA4C7ezdwfADwAePuz7p7NJhcTWIErLCk8v9fRmL7gcT2dI0dH1R2gLj7Xnd/NXjcDmwiMW5vrlgGPOQJq4FRZjYxg+9/DbDN3U/3m+hnxN1fJDEuRLLk7aivPFoMrHL3A+5+EFgFLDmV987aQD+J3gat7rmxjwUOJQVHb23S6XKg2d239rHcgWfNbF0wUHam3BX8yfvDPv7ES2VdDqTbSezJ9SYT6yyV//+7BkAHjg+AnhFBF88FwMu9LL7EzF43s2fMbG6maqL/zybs7Wo5fe9chbXOxrv73uBxE9DbwMhnvN4yOkh0T2b2HDChl0VfcfdfZLqe3qRY462cfO/8MndvNLNxwCoz2xz8Fh+w2oDvAV8j8cP3NRJdQref6XueaV3H15mZfQWIAo/28TIDss5yiZkNB34O/LW7t/VY/CqJLoUjwfGRp4GZGSotaz+b4FjZUuDLvSwOc52d4O5uZgNyvnioge7u157G01IZtHo/iT/zioK9qt7apKVGSwyK/WFg0UleozG4bzGzp0j8qX/GPwCprj8z+3fgl70sSmVdpr0uM/sk8CHgGg86D3t5jQFZZz2cygDoDZbBAdDNrJhEmD/q7v/Vc3lywLv7SjP7NzOrcPcBvwhVCp/NgGxXKboBeNXdm3suCHOdAc1mNtHd9wbdTy29tGkk0c9/3GQSxxBTlotdLiuA5cHZB9NJ/IZ9JblBEBIvkBiwGhIDWA/UHv+1wGZ3b+htoZkNM7Py449JHBTc0FvbdOrRZ/mnfbxnKgOAp7uuJcDfAUvdvaOPNplaZ1k5AHrQR/8DYJO7f7uPNhOO9+Wb2UUkfpYz8Ysmlc9mBfDx4GyXi4HDSd0NA63Pv5bDWmeB5O2orzyqBa43s9FBF+n1wbzUDfQR3zM4UvynJPqQuoBmoDZp2VdInJ2wBbghaf5KYFLweAaJoK8HfgaUDlCdPwY+02PeJGBlUh2vB7c6Et0OmVh/DwNvAm8EG9PEnrUF0zeSOItiWyZqCz6PPcD64PZAz7oyuc56+/8D95H4hQNQFmw/9cH2NCMD6+gyEl1lbyStpxuBzxzf1oC7gnXzOomDy5dmaLvq9bPpUZsB9wfr9E2SzlIb4NqGkQjokUnzMr7OSPxC2QtEggy7g8Rxl+eBrcBzwJigbQ3wH0nPvT3Y1uqBT53qe+ur/yIieSIXu1xERKQXCnQRkTyhQBcRyRMKdBGRPKFAFxHJEwp0EZE8oUAXEckT/x+RA0eeVZgAAAACSURBVE9qpn1mNgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AISR_lIeHzY"
      },
      "source": [
        "・線形な関数は加法性、斉次性を満たすが、非線形な関数は加法性、斉次性を満たさない。\n",
        "\n",
        "・斉次性とは同次性ともいう。多項式において、すべての項が等しいときのことをいう。\n",
        "\n",
        "加法性： f(x + y) = f(x) + f(y)\n",
        "斉次性： f(kx) = kf(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9idyhL9WgR-G"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxxXmzNzidrO"
      },
      "source": [
        "活性化関数とは、前の層のノードからの出力を次の層に伝える際に活性化関数が使われる。あらゆる入力値を別の数値に変換して出力する関数。ニューラルネットワークの隠れたニューロンに対して、非線形のモデル化能力を与えることが活性化関数の目的。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR0yDeYfknT1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co7p1HFIvRMP"
      },
      "source": [
        "# Section3:出力層"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW0AZhuevYf1"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79g_D2pR30db"
      },
      "source": [
        "出力層の活性化関数は、回帰問題と二値分類と他クラス分類のどれを使うかによって、それぞれに適した活性化関数を使用しなければならない。それに合わせてどの誤差関数を使用するかも決まってくる。\n",
        "\n",
        "・回帰問題の活性化関数は恒等写像を使い、誤差関数は二乗誤差を用いる。\n",
        "\n",
        "・二値分類の活性化関数はシグモイド関数を使い、誤差関数は交差エントロピーを用いる。\n",
        "\n",
        "・他クラス分類の活性化関数はソフトマックス関数を使い、誤差関数は、交差エントロピーを用いる。\n",
        "\n",
        "このように問題に合った活性化関数と誤差関数のペアを間違えなえれば、あるていどの学習成果は得られる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lECCUXcT6Kp7"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUORJVkUeaSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c2b15a-7bbb-4777-9380-cda2f8320d7f"
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "exp_a = np.exp(a) #指数関数\n",
        "print(exp_a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.34985881 18.17414537 54.59815003]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5n2YMZW7Ldq",
        "outputId": "f452eb59-69c5-4112-c90c-5c0764d39fc3"
      },
      "source": [
        "sum_exp_a = np.sum(exp_a) #指数関数の和\n",
        "print(sum_exp_a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74.1221542101633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUCIcet57dW2",
        "outputId": "710114c0-8612-4a71-eba6-febccc309a06"
      },
      "source": [
        "y = exp_a / sum_exp_a\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01821127 0.24519181 0.73659691]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjrCRLeD7uay"
      },
      "source": [
        "#ソフトマックス関数\n",
        "def softmax(a):\n",
        "    exp_a = np.exp(a)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjKQ9uZY9CJM"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oHpqOFa9HG6"
      },
      "source": [
        "誤差関数について\n",
        "\n",
        "二乗する理由は、引き算を行うだけでは、各ラベルでの誤差で正負両方の値が発生し、全体の誤差を正しく表すのに都合が悪い。二乗してそれぞれのラベルでの誤差を性になるようにするため。要するに誤差和を足し合わせるとゼロになってしまうので、それを避けるため。\n",
        "\n",
        "1/2する理由は、実際にネットワークを学習する時に行う誤差伝播の計算で、誤差関数の微分を用いるが、その際の計算式を簡単にするため。本質的な意味はない。要するに微分をする際、式の後ろの乗数の2が前に来た時に1/2と打ち消し合って式がスッキリする。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATpcMshxE_3E"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHtJRFpAIe5-"
      },
      "source": [
        "出力層のニューロンの数は、解くべき問題に応じて、適宜決める必要がある。回帰分析では実数値が出力され、分類問題では出力層のニューロンの数は分類したいクラス数に設定するのが一般的で、確率の集合が出力される。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FNgJDv2JMwX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO45xppydHnl"
      },
      "source": [
        "# Section4:勾配降下法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEm1GTSdxPwp"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k11Un_MHdetc"
      },
      "source": [
        "勾配降下法には3つの手法、勾配降下法、確率的勾配降下法、ミニバッチ勾配降下法がありニューラルネットワークを学習させる手法のことをいう。誤差関数を最小にするW（重み)やｂ(バイアス)を見つけることが勾配効果法の目的。\n",
        "\n",
        "勾配降下法\n",
        "\n",
        "$W^{(t+1)} = W^{t} - \\varepsilon \\nabla E$\n",
        "\n",
        "$\\nabla E = \\frac{\\partial E}{\\partial W} = \\bigl[\\frac{\\partial E}{\\partial w_1} \\cdots \\frac{\\partial E}{\\partial w_M} \\bigl]$\n",
        "\n",
        "$\\varepsilon$:学習率\n",
        "\n",
        "学習率が大きすぎる場合、最小値にいつまでもたどり着かずに発散してしまう。要は最小値を大きく通り越してしまっている現象がおきている。また、学習率が小さすぎる場合には発散はしないが、収束するまでに時間が掛かるし、極小値におさまってしまう。\n",
        "\n",
        "学習率の制御をより良くするために改良されたアルゴリズムに、Momentum AdaGrad Adadelta Adam がある。非常によく使用されるのはアダムである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMvqhGBZdRGe"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1J9Nc-CJNuY"
      },
      "source": [
        "#勾配降下法\n",
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "    return x    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWfxIW1i0WMY"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "aEanpf2N640V",
        "outputId": "5e15c41e-1534-4fc3-a623-7e8ec8eed9d7"
      },
      "source": [
        "\"\"\"\n",
        "learning_rate = 0.07\n",
        "epoch = 1000\n",
        "network = init_network()\n",
        "random_datasets = np.random.choice(data_sets, epoch)\n",
        "for dataset in random_dataset:\n",
        "    x, d = dataset['x'], dataset['d']\n",
        "    z1. y = forward(network, x)\n",
        "    grad = backward(x, d, z1, y)\n",
        "    for key in ('W1', 'W2', 'b1', 'b2'):\n",
        "        network[key] -= learning_rate * grad[key]\n",
        "    loss = functions.mean_spuared_error(d, y)\n",
        "    losses.append(loss)\n",
        "lists = range(epoch)\n",
        "plt.plot(lists, losses, ' . ')\n",
        "plt.show()            \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nlearning_rate = 0.07\\nepoch = 1000\\nnetwork = init_network()\\nrandom_datasets = np.random.choice(data_sets, epoch)\\nfor dataset in random_dataset:\\n    x, d = dataset['x'], dataset['d']\\n    z1. y = forward(network, x)\\n    grad = backward(x, d, z1, y)\\n    for key in ('W1', 'W2', 'b1', 'b2'):\\n        network[key] -= learning_rate * grad[key]\\n    loss = functions.mean_spuared_error(d, y)\\n    losses.append(loss)\\nlists = range(epoch)\\nplt.plot(lists, losses, ' . ')\\nplt.show()            \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVt5iyn3B4R3"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKKiXG_FD4fL"
      },
      "source": [
        "学習率の値は0.01や0.001など、前もって何らかの値に決める必要がある(ハイパーパラメータ)。ニューラルネットワークの学習においては、学習率の値を変更しながら、正しく学習ができているかどうか、確認作業をするのが一般的。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvLqQDv6Edtj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsAk5xdAEill"
      },
      "source": [
        "# Section5:誤差逆伝播法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMmbWF4jEx4d"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAV7tJ6jE0q7"
      },
      "source": [
        "誤差逆伝播法\n",
        "\n",
        "算出された誤差を、出力層側から順に微分し、前の方の層へと伝播させる。最小限の計算で各パラメータでの微分値を解析的に計算する手法。\n",
        "\n",
        "数値微分\n",
        "\n",
        "プログラムで微小な数値を生成し疑似的に微分を計算する一般的な手法。計算結果の誤差から微分を逆計算することで、不要な再帰的計算を避けて微分を算出できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjCxJsGC7ebQ"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiePm-HlEfE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb7c30a-d44f-46e9-fad0-bb6fc6df0c17"
      },
      "source": [
        "import numpy as np\n",
        "e2_1 = 0.8\n",
        "e2_2 = 0.5\n",
        "w2_11 = 2.0\n",
        "w2_21 = 1.0\n",
        "w2_12 = 3.0\n",
        "w2_22 = 4.0\n",
        "e3 = np.array([e2_1, e2_2])\n",
        "e2 = np.array([[w2_11 / (w2_11 + w2_12), w2_21 / (w2_21 + w2_22)], \n",
        "                [w2_12 / (w2_11 + w2_12), w2_22 / (w2_21 + w2_22)]])\n",
        "print(np.dot(e2, e3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.42 0.88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl7BCUt99ZvW"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GffxeFxI-gTa"
      },
      "source": [
        "delta2 = funcions.d_mean_spuared_error(d, y) \n",
        "\n",
        "delta1 = np.dot(delta2, W2. T) * functions. d_sigmoid(z1)\n",
        "\n",
        "delta1 = delta1[np.newaxis, :]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUCv47EOA2wh"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DliyVz14A-Qc"
      },
      "source": [
        "ニューラルネットワークにおける代表的なパラメータ探索手法が、勾配降下法である。勾配降下法では、目的関数を各パラメータで偏微分した値が必要となるが、この偏微分値を効率よく求めていく方法が(ア)である。(ア)の根幹の数学的技術が微分の連鎖律であり、例えばg(f(x))に対して連鎖率を適用すると、gのｘによる偏微分が($\\frac{\\partial g}{\\partial f} \\frac{\\partial f}{\\partial x}$)で与えられている。この連鎖率を用いて、出力層から入力層まで正解との誤差を伝えていく。\n",
        "\n",
        "(ア)・・・バックプロパゲーション"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-hv_XdAH5fc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq5HqGScIu8B"
      },
      "source": [
        "# **深層学習day2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGAPI1UkI2xB"
      },
      "source": [
        "# Section1:勾配消失問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYYKibkPJFhz"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh1SwPQcTcZQ"
      },
      "source": [
        "勾配消失問題とは、誤差逆伝播法が下位層に進んでいくにつれて、勾配がどんどん緩やかになっていく。そのため、勾配降下法による、更新では下位層のパラメータはほとんど変わらず、訓練は最適解に収束しなくなる。主な原因はシグモイド関数の微分値が最大で0.25であるため、微分同士を掛け合わせる数が多くなるほど0に近づいていくからである。勾配消失問題の解決方法は3つあり、活性化関数の選択、重みの初期設定、バッチ正規化を工夫することである。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgig38uwYSoH"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "CDUxPO7hZ0JA",
        "outputId": "296bfc11-f5c4-4dff-c772-57eb4b7eade6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "x = np.linspace(-10, 10)\n",
        "y = sigmoid(x)\n",
        "plt.plot(x, y)\n",
        "dy = (1 - sigmoid(x)) * sigmoid(x)\n",
        "plt.plot(x, dy)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnZrKQgGFJ2JcEiiyKCEak1Vp3ARdc2opLa7Wt7W1t6+92s8u1Vtve623rrW1tlVZra624FC1aZHGhrlhAFtkNi5BAQhIkQAJZZr6/P85EhpBAQiY5M5P38/GYx5zlm5lPzpx55+R7NnPOISIiyS/gdwEiIhIfCnQRkRShQBcRSREKdBGRFKFAFxFJESG/3jg3N9fl5+f79fYiIklp2bJlFc65vObm+Rbo+fn5LF261K+3FxFJSmb2fkvz1OUiIpIiFOgiIilCgS4ikiIU6CIiKUKBLiKSIo4Z6Gb2sJntMrPVLcw3M/u1mRWZ2Sozmxj/MkVE5Fhas4X+CDDlKPOnAiOjj1uA37e/LBERaatjHofunHvVzPKP0mQ68BfnXYd3sZn1NLMBzrmdcapRRFJUQzhCXThCbX3sc5i6Bkc44qiPRGgIOxrCEeojjnAkQjgC4Ygj4hwNEUckOhxxeM+RQ8POORwQiUSfHd40B47GZw4bb9R4afHGae7D6Y3jh89v6rDJTRqdP6Yf44f0bMeSa148TiwaBGyPGS+OTjsi0M3sFryteIYOHRqHtxYRvzjn2FNTz659tZTvq6Wyupa9B+rZe7CBqgP17D1QT9WBevYdbKCmroGaujAH6sPec3Q4HOk692MwOzTc94TMhA30VnPOzQRmAhQWFnadT1IkCTnn2LWvli0V1WytqGZrZQ1bK6rZWXWA8n21lO+vpT7c/Nc4IxTghG5p5HRLo0dmiKz0IL2zM8hKD5KVHqRb9DkjFCQjFCA9+sgIBb3hoBEMBAgFjbTG5+i0oBmBAAQDRihgBMx7BAOGGR+OBwJgGAEDs+gzhgXA8KZ5z9Hp0cD98Dl2Go3zrMn44dP9Fo9ALwGGxIwPjk4TkSQRjjg2le9nxbY9LN++h1XFe9hcXs2B+vCHbdKCxpDeWQzq2Y0RfbvTt0cmeT0y6Bt99Omezgnd0jghM43MtKCPv03XFY9AnwPcamazgDOAKvWfiyS2cMSx7P0PWLRhF8u37eHdkir21zYA0CMzxPjBPbl2Uh/yc7PI75NNQW42A3IyCQV1pHMiO2agm9njwDlArpkVAz8C0gCccw8Ac4FpQBFQA9zUUcWKyPGrbQjzZlEl89eU8uK6Mir21xEKGGMHnsBVEwcxfnBPTh3ak4I+2QQCidGFIG3TmqNcrj3GfAd8NW4ViUjcOOd4vaiCWUu2s2j9LqrrwnTPCHHOqDwuPqk/54zKo0dmmt9lSpz4dvlcEek4DeEIc1eX8uC/NrFmx156Z6dz2fiBXHxSfz72kT5khNTHnYoU6CIp5EBdmKeWbecPr21m++4DDM/L5p6rx3HFhEEK8S5AgS6SAsIRx5/e2MLvFm1id3UdE4b25IeXjOXCMf3UH96FKNBFktzm8v18++lVLHv/Az4+MpevnTeS0/N7Jcyx0dJ5FOgiSapxq/zn8zeQmRbkV9ecyvRTByrIuzAFukgS2lpRzbefXsmSrR9wwZi+/OzKcfQ9IdPvssRnCnSRJPPXxe/zk3+uJT0Y4JefGs9VEwdpq1wABbpI0nDOce/Cjfzm5SI+cWIe91x9Cv1ztFUuhyjQRZKAc46f/HMdD72+hRmnD+GnV44jqKNXpAkFukiCC0ccP3x2NY//exs3nZnPHZeOVReLNEuBLpLAGsIRvvXUSp5dsYOvnjuCb100SmEuLVKgiySo2oYwX398OfPXlPHti0fx1XM/4ndJkuAU6CIJqK4hwpceXcaiDeXccelYbj6rwO+SJAko0EUS0D3z1rNoQzk/u3Ic152h2zVK6+hq9SIJZv6aUh56fQs3fnSYwlzaRIEukkC2767hW0+t5JTBOXz/kjF+lyNJRoEukiBqG8J89W/vAHD/dRN1uVtpM/WhiySI/567nlXFVTxww2kM6Z3ldzmShLSFLpIA5r67k0fe3Mrnzypgysn9/S5HkpQCXcRn71dW892nV3HqkJ58d8pov8uRJKZAF/HRwfowX3nsHQIB47fXTSA9pK+kHD/1oYv4aOarm1mzYy9//Gwhg3up31zaR5sDIj4p23uQ3y/axLRx/blgbD+/y5EUoEAX8ckvF2wgHHHqN5e4UaCL+GDNjiqeWlbM587MZ1ifbL/LkRShQBfpZM45fvrPdfTslqYrKEpcKdBFOtlL63bx5qZKbrvgRHK6pfldjqQQBbpIJ6oPR/jZC+sYnpetC29J3CnQRTrR397exubyan4wbQxpQX39JL60Rol0kqqaen714kbO/Egfzhvd1+9yJAUp0EU6yW9feY89B+r5wTTd5Fk6RqsC3cymmNkGMysys9ubmT/UzF4xs+VmtsrMpsW/VJHk9X5lNY+8uZVPnzaEsQNP8LscSVHHDHQzCwL3A1OBscC1Zja2SbMfAk865yYAM4DfxbtQkWR230vvEQoE+OZFJ/pdiqSw1myhTwKKnHObnXN1wCxgepM2Dmjc7MgBdsSvRJHktmvfQZ5buYNPFw6m7wmZfpcjKaw1gT4I2B4zXhydFutO4AYzKwbmAl9r7oXM7BYzW2pmS8vLy4+jXJHk89fF22iIOD53ZoHfpUiKi9dO0WuBR5xzg4FpwKNmdsRrO+dmOucKnXOFeXl5cXprkcR1sD7MY4vf5/zRfSnI1Sn+0rFaE+glwJCY8cHRabE+DzwJ4Jx7C8gEcuNRoEgym7NiB5XVddysrXPpBK0J9CXASDMrMLN0vJ2ec5q02QacD2BmY/ACXX0q0qU553j4jS2M7t+Dj47o43c50gUcM9Cdcw3ArcB8YB3e0SxrzOwuM7s82uybwBfNbCXwOPA555zrqKJFksFbmypZX7qPm88q0HHn0iladcci59xcvJ2dsdPuiBleC5wZ39JEkttDr2+hT3Y6l48f6Hcp0kXoTFGRDrClopqX1u/i+snDyEwL+l2OdBEKdJEO8MgbW0gPBrhhsq6oKJ1HgS4SZ1UH6nlqWTGXjR9I3x46kUg6jwJdJM6eWLKNmrowN5+V73cp0sUo0EXiqCEc4c9vvs/k4b05aWCO3+VIF6NAF4mjBWvLKNlzQCcSiS8U6CJx9Oc3tzK0dxbnj+nndynSBSnQReJk++4a3t6ym2tOH0IwoBOJpPMp0EXi5B8rvEsc6UQi8YsCXSQOnHPMXl7CpILeDOmd5Xc50kUp0EXiYFVxFZvLq7lqQtNbBYh0HgW6SBw8s7yE9FCAqeMG+F2KdGEKdJF2qg9HeG7lDi4c04+cbml+lyNdmAJdpJ1e3VhOZXUdV6q7RXymQBdpp9nLS+iVlcbZJ+q2iuIvBbpIO+w9WM/CtWVcNn4g6SF9ncRfWgNF2uGFd3dS1xBRd4skBAW6SDvMfqeEgtxsTh3S0+9SRBToIserZM8B3t6ymysnDNI9QyUhKNBFjtOzy71T/a84Vd0tkhgU6CLHwTnHM8tLKBzWi6F9dKq/JAYFushxWF2yl6Jd+7lyorbOJXEo0EWOw+zlxaQHA1w6TldWlMShQBdpo3DE8dzKHZw3ui85WTrVXxKHAl2kjZZs3U3F/jouHa8LcUliUaCLtNG81aWkhwKcO6qv36WIHEaBLtIGkYhj/ppSzh6ZR3ZGyO9yRA6jQBdpg1UlVeysOsjUk/v7XYrIERToIm0wb3UpoYBxwZh+fpcicgQFukgrOeeYt3onHx3RR0e3SEJqVaCb2RQz22BmRWZ2ewttPm1ma81sjZn9Lb5livhvQ9k+tlbWMEXdLZKgjrlXx8yCwP3AhUAxsMTM5jjn1sa0GQl8DzjTOfeBmWn3v6ScF94txQwuHKvuFklMrdlCnwQUOec2O+fqgFnA9CZtvgjc75z7AMA5tyu+ZYr4b/6aUk4f1pu+PTL9LkWkWa0J9EHA9pjx4ui0WCcCJ5rZG2a22MymNPdCZnaLmS01s6Xl5eXHV7GID7ZUVLO+dB8Xq7tFEli8doqGgJHAOcC1wB/M7Igr/jvnZjrnCp1zhXl5uv+iJI95q0sB1H8uCa01gV4CDIkZHxydFqsYmOOcq3fObQE24gW8SEqYt6aUUwbnMKhnN79LEWlRawJ9CTDSzArMLB2YAcxp0uZZvK1zzCwXrwtmcxzrFPHNjj0HWLl9j7bOJeEdM9Cdcw3ArcB8YB3wpHNujZndZWaXR5vNByrNbC3wCvBt51xlRxUt0pnmr4l2t5ykQJfE1qqLUTjn5gJzm0y7I2bYAf8ZfYiklHmrSzmxX3eG53X3uxSRo9KZoiJHUbG/liVbdzPlZF0qVxKfAl3kKBauLSPi1N0iyUGBLnIU81aXMqxPFmMG9PC7FJFjUqCLtKDqQD1vbqpgykn9MTO/yxE5JgW6SAsWbdhFfdhxkbpbJEko0EVasGBtGXk9Mpgw5IiTnkUSkgJdpBm1DWH+taGcC8b0JRBQd4skBwW6SDMWb97N/toGXSpXkooCXaQZC9aUkpUe5GMjcv0uRaTVFOgiTUQijhfXlXH2yDwy04J+lyPSagp0kSbeLamibG+tulsk6SjQRZpYuLaMYMA4b7TupCjJRYEu0sTCtWUUDutFr+x0v0sRaRMFukiMbZU1bCjbp+4WSUoKdJEYC9Z61z6/aKzODpXko0AXibFgbRmj+/dgaJ8sv0sRaTMFukjU7uo6lm7dre4WSVoKdJGol9fvIuJQoEvSUqCLRC1cW0r/EzIZNyjH71JEjosCXQQ4WB/m1Y0VXDC2r659LklLgS4CvFFUwYH6MBfq6BZJYgp0EbyTibpnhJg8vLffpYgcNwW6dHnh6MW4PjEqj4yQLsYlyUuBLl3eiu0fULG/jot0dIskOQW6dHnz15SRFjTOGaWLcUlyU6BLl+acY97qUj42Ipecbml+lyPSLgp06dLW7dzHtt01TDlZR7dI8lOgS5c2b/VOAqazQyU1KNClS5u3ppTT83uT2z3D71JE2k2BLl3WpvL9bCzbr+4WSRkKdOmy5q32rn1+8UkKdEkNrQp0M5tiZhvMrMjMbj9Ku6vNzJlZYfxKFOkY89eUMn5ITwb27OZ3KSJxccxAN7MgcD8wFRgLXGtmY5tp1wP4BvB2vIsUibfiD2pYVVzFVHW3SAppzRb6JKDIObfZOVcHzAKmN9PubuAe4GAc6xPpEPPXlAHqbpHU0ppAHwRsjxkvjk77kJlNBIY45/55tBcys1vMbKmZLS0vL29zsSLxMn91KaP796AgN9vvUkTipt07Rc0sANwLfPNYbZ1zM51zhc65wry8vPa+tchx2bXvIEve362jWyTltCbQS4AhMeODo9Ma9QBOBhaZ2VZgMjBHO0YlUS1cW4ZzKNAl5bQm0JcAI82swMzSgRnAnMaZzrkq51yucy7fOZcPLAYud84t7ZCKRdpp3upSCnKzGdWvh9+liMTVMQPdOdcA3ArMB9YBTzrn1pjZXWZ2eUcXKBJPVTX1vLWpkotP6q9bzUnKCbWmkXNuLjC3ybQ7Wmh7TvvLEukYL64royHi1N0iKUlnikqX8sLqUgbkZDJ+cI7fpYjEnQJduozq2gZefa9c3S2SshTo0mUs2lBOXUNEZ4dKylKgS5fxz3d3kNs9ncL83n6XItIhFOjSJVQdqOfFdbu49JSBBAPqbpHUpECXLmHuuzupa4hw1cRBx24skqQU6NIlPPNOCSPyshk3SEe3SOpSoEvK2767hn9v3c1VEwfr6BZJaQp0SXnPLvcuPXT5+IE+VyLSsRToktKcczyzvIRJBb0Z0jvL73JEOpQCXVLayuIqNldUc9UE7QyV1KdAl5T27PIS0kMBpo4b4HcpIh1OgS4pqz4c4bmVO7hwTD9yuqX5XY5Ih1OgS8p6dWM5ldV1XKnuFukiFOiSsmYvL6FXVhpnn6jbHUrXoECXlLT3YD0L15Zx2fiBpIe0mkvXoDVdUtIL0VP91d0iXYkCXVLS7HdKKMjN5tQhPf0uRaTTKNAl5RR/UMPbW3Zz5YRBOtVfuhQFuqScf6zYAaDuFulyFOiSUiIRx9PLijk9v5dO9ZcuR4EuKWXRxl1sqajmhsnD/C5FpNMp0CWlPPz6VvqdkME0neovXVDI7wJE4mV96V5eL6rg2xePIi3Yym0V52DNM7D8rxBpOHJ+MB0Kb4bR0+JbrEgH0Ba6pIw/vb6VzLQA100a2rof2L0FHvskPH0T7N4MDbVHPio2wKxrYdb1UFXcsb+ASDtpC11SQuX+Wp5ZUcInTxtMr+z0ozduqIM3fw2v/hwCIZjyP3D6FyHYzNehoQ4W3w+L7oHfToJzvw9nfLn5tiI+0xa6pITH3t5GXUOEm8/MP3rDrW/AA2fBy3fDyIvg1iUw+T9aDuhQOpz1/+CriyH/TFjwA/jDOVC8LN6/gki7KdAl6dU2hHl08ft84sQ8PtK3R/ONnIOX7oZHpkHDAbjuSbjmUTihlbel65Xv/cyn/wLVFfDH8+G1e+P2O4jEg/5vlKT3z1U7Kd9Xy82fKmi50au/gNd+ARNugKk/h/TjOEbdDMZOhxHnwXO3wUs/hrRu3ha+SAJQoEtSc87x0Otb+Ejf7pw9Mrf5Rot/D6/8BE6ZAZf9BgLt/Mc0owdc+SCEa2He7ZDeHSZ+pn2vKRIHrVqzzWyKmW0wsyIzu72Z+f9pZmvNbJWZvWRmOqtDOsW/t+xmzY693HxmQfPXbXnnUS90R18K0+9vf5g3Cobg6odgxPnw3Ndh9ez4vK5IOxxz7TazIHA/MBUYC1xrZmObNFsOFDrnTgGeBv433oWKNOfhN7bQMyut+eu2rJ7the2I8+GTD8f/yJRQBlzzVxgyGWZ/ETbOj+/ri7RRazZXJgFFzrnNzrk6YBYwPbaBc+4V51xNdHQxMDi+ZYocaVtlDQvWlnH9GUPplh48fObGBV7IDpnshW4oo2OKSM+C62ZBv5Phic/Allc75n1EWqE1gT4I2B4zXhyd1pLPAy80N8PMbjGzpWa2tLy8vPVVijTjkTe3EjTjM5PzD5+x5TV48jNeyF436/h2gLZFZg7cMBt6F8Dj10Lx0o59P5EWxPWwRTO7ASgEft7cfOfcTOdcoXOuMC9P93mU47e7uo4nl27nklMG0D8n89CMiiLvrM5e+V7IZuZ0TkHZfeAzz0J2LvztGtiz/dg/IxJnrQn0EmBIzPjg6LTDmNkFwA+Ay51ztfEpT6R59724kQP1YW499yOHJh7c652mHwzB9U95IduZThgA1z8N4TqYdR3U1Rz7Z0TiqDWBvgQYaWYFZpYOzADmxDYwswnAg3hhviv+ZYocUrRrP399exvXTRrKyH7RE4kiEZh9C1Rugk/9GXq28nou8ZY7Eq7+I5S+C3Nu9U5oEukkxwx051wDcCswH1gHPOmcW2Nmd5nZ5dFmPwe6A0+Z2Qozm9PCy4m023/PXUdWWpDbLhh5aOKin8HGF7zrshR83L/iAE68GM77Iaz+O7xxn7+1SJfSquO4nHNzgblNpt0RM3xBnOsSadbr71Xw0vpdfG/qaPp0jx65suZZ70JbEz4Dk77ob4GNPv5Nbyv9xTu9nbMj9RWRjqdruUjSCEccP/nnWgb36saNH8v3Jpauhmf/AwZPgkt+6Z2enwjM4IrfeWH+9M1eV5BIB1OgS9J4etl21pfu4/apo8lMC0J1pbcTNDPHu9BWRx1rfrzSs2HGYxAIeoczHtzrd0WS4hTokhSqaxv4xYKNTBzak0vGDYBwPTz9OdhX6p041KO/3yU2r9cw+PSfobLI22kbifhdkaQwBbokhQf/tYnyfbX88NKxGMAL3/HOyrzsPhhc6Hd5R1dwNkz5b2+n7Ut3+l2NpDBdbVES3o49B5j52mYuHz+QiUN7weIHYOnDcOY34NTr/C6vdSbdAuXrvaNeckfBhOv9rkhSkLbQJeH9Yv4GIg6+M2UUvLcQ5n8PRl0C59/pd2mtZwZT/xcKPgHPfcO7c5JInCnQJaG9vbmS2ctL+MJZBQyufx+eugn6ngRXzYzfpXA7SzDN60/vNQyeuMG7MbVIHCXZN0K6kor9tXzt8eUMz83mK2f09K6R0nh1w4zufpd3fLr18m5l5yLwtxlwsMrviiSFKNAlIYUjjttmraDqQD2/m3ES3WffCPvLYMbjkJPkV2fuM8I7Mmf3JnjqcxBu8LsiSREKdElIv325iNeLKvjxZWMZveS/YPti70Sdwaf5XVp8FHwcLrkXNr3s7RMQiQMd5SIJ582iCn710kauPHUg1+z5A6x8HM75Hpx8td+lxddpN0LFRnjrt5CdB5/4jt8VSZJToEtC2bXvIF+ftYLhfbK4p9cz2Fu/gdO/AJ/4rt+ldYwL74KaSnjlp94ZpR//pt8VSRJToEvCCEcc33h8Bftr65k3/lXS37oPTrsJpv48ca7REm+BoHfz6kgYXroLAiHv+HqR46BAl4Rx34sbeWtzJc+f8ga5y+73rp54yb3Jd3hiWwWCcMXvwYVh4R1eqH/0q35XJUlIgS4JYcGaUn7zShG/H/oyJ2/8I5x6PVz269QP80bBEFw509tSn/99L9TP+JLfVUmSUaCL755ftYPbZq3gzl4LmLrrETjlGrj8N10nzBsFQ97djiIN3rVqLJA413eXpNDFvjGSaJ5aup1vPL6Me3r9gxtrHoGTP+l1PwSCfpfmj2AafPJPMGoazP0WvHavbmMnraZAF988+tZW7n76Lf6e82uurp7l9Zlf+WDXDfNGoXT41CPeH7eXfuydfFS73++qJAmoy0V88eC/NvHUvBdZ0P0++tWVeXcbKvx86h7N0lahDK/7ZcB4ePFH3vHqMx6D3sP9rkwSmLbQpVM557h34Ubemf8oz2f+iH4Z9diNz3vHmivMD2cGZ34dbvg77NsJM8+B9170uypJYAp06TTVtQ18/+8rCf3rpzyY/n9kDBiL3bIIhn3U79IS24jz4JZFkDMEHvuk+tWlRQp06RRvbqrgy/f+lemrvszXQ8/iTr0Bu2ku5Azyu7Tk0CsfPr8ATr7K61f/69W68bQcQX3o0qFq6hr41fPL6PvO//FIaD4uswdM+Q024TPqYmmr9Gy4+iEYMtk7q/R3k+FjX/MuF5Ce7Xd1kgAU6NJh3t5UwYInfsOXah8hL1RF+NTPErrwR5Ddx+/SkpcZnHELjJ3unVX62i9h5RNw8U+9afoj2aWpy0XibvvuGn772NPYn6fxX3W/IitvGPbFlwhd8WuFebz06AdXPQg3zfNumvHUjfDoFVC21u/KxEfmfNq5UlhY6JYuXerLe0vHWFu8m7deeJSTts9icmAt1aGehC76MRmFn+16Z312pnADLPsTvHy3dwekEefBpC/ByIu03FOQmS1zzhU2O0+BLu3hnGPJ2iI2L3yAsz54lsFWwZ70/gQmfYETzvyCt/UonaO6EpY9DEse8g5z7FUAk26BCddDZo7f1UmcKNAl7rbsKGfdm88T2vg8Z9f+i0yrp7hnIb3O/TrZ4y7V2Z5+CtfDuufg7Qe9Oz2lZcMpn4LRl0H+WZCW6XeF0g4KdGk35xzrN25k+9vP0GPbi5xav5JuVkcN3SgZcglDp9xGxqBxfpcpTe1YAf+eCWuegfoaL9xHnAsnToETL4buff2uUNpIgS5tdrCuns3rV1Cx/i3cjnfoX7WCUW4LALuC/agYeB59C68g96RzvdPUJbHVH4Atr8HGed5jb4k3feBEGHIGDJroDfcern73BKdAlxaFwxFKd7xP5bYN7Nu5EVe2lpwPVlNQX0R3OwBADZkUZ57IwfxzGTb5anKGnaLD45KZc1D6LmycD5te8rbiG7zPmowcGDjeC/e80dC7wAv57Dx95gmi3YFuZlOA+4Ag8Efn3P80mZ8B/AU4DagErnHObT3aayrQO144HGZ3xU6qdhWzv7KE2j07CVeVYftLSa/eQc+DxfQP7yTbaj/8mToXYlv6CKp6jyN96GkMGPMxcvPHqU88lYUboHw97FgOO96BknegbA1E6g+1Se9+KNxzhnhdNd37RZ/7e8PdemnrvhO0K9DNLAhsBC4EioElwLXOubUxbb4CnOKc+7KZzQCudM5dc7TX7WqBHgmHCYcbCIcbiIQbCIfDRBrqqa+vI9xQR7i+nnBDLeGGesL1ddTXHSRcd5BI/UEa6muJ1B8kUneQSG01rq4aV1cD9dVYfQ2BhgOE6vaS3rCPzPB+siL76B6ppjs1BOzIz7eGDCoDuezOHEJtj3wCfYaTNeBE8oaOoc/A4QTS0n1YQpJQGuqgajvs3nz4o3IT7N1xaIs+lgUg4wTviJpuPb3nzBxvqz89C9KyvDNa07Ki49led10oA4LpEMo8NBxM9+7aFAxBIM27TnwgFH0EwYLecyDU5f5zOFqgt+ZM0UlAkXNuc/TFZgHTgdgzGKYDd0aHnwZ+a2bmOqA/Z8ns++i7+g8xUw69hdH821mTMg61c4eNW+w05z4ct+ijsW1zjwAOcxHvGUeAQ8NBIgTMEQDS2vPLN1HnQhywDGrJoCbQnYPB7lSn57EnfTjh9BxcxgkEuueR1nMA3XoPJCd3MD37Diarew5ZwJA41iIpJpQOfUZ4j6acg7r9sH8X7CuF/WXecHU51O6FA3u84+EPVkHFe3BwL9RXQ13N4Vv9cWPRkA80eQS9L7UFvDYW8ML/w3Fr4TnmdT/8YxF9Ptb4EaXFTo8ZPue7cPLVx/8rt6A1gT4I2B4zXgyc0VIb51yDmVUBfYCK2EZmdgtwC8DQoUOPq+C0HnlUZh1+TWgXu6Ba/Gtth7c9ol10fuOH2jjNrMnPGK5xxeDwlcPFrEgudsX5cEsiAIEg1rh1EUzDgiEsugUSCKZhoTQCoXQCaZkE0zIIpWcSTO9GKD2TtPRuZGb1ICOrO92ye5Celo62paXTmUFGD+/RXOAfTbjeO9qmrsZ7bqiFcK333PgI10K4zru/arje+yMQrvduzRdp8Ka7MEQi3rgLe9Nw4CLR+dFhF3FhfL4AAAaoSURBVDk0vXFa7Dguug3nDo1DM8O0YrypmOlN22T2bNtya6VOvZaLc24mMBO8LpfjeY1TL7wOLrwurnWJSCcJpkEwRyc6dZDW7MEo4fD/zgdHpzXbxsxCQA7ezlEREekkrQn0JcBIMysws3RgBjCnSZs5wI3R4U8CL3dE/7mIiLTsmF0u0T7xW4H5eIctPuycW2NmdwFLnXNzgIeAR82sCNiNF/oiItKJWtWH7pybC8xtMu2OmOGDwKfiW5qIiLSFzgIQEUkRCnQRkRShQBcRSREKdBGRFOHb1RbNrBx4/zh/PJcmZ6EmCNXVNqqr7RK1NtXVNu2pa5hzLq+5Gb4FenuY2dKWLk7jJ9XVNqqr7RK1NtXVNh1Vl7pcRERShAJdRCRFJGugz/S7gBaorrZRXW2XqLWprrbpkLqSsg9dRESOlKxb6CIi0oQCXUQkRSRsoJvZp8xsjZlFzKywybzvmVmRmW0ws4tb+PkCM3s72u6J6KV/413jE2a2IvrYamYrWmi31czejbbr8BupmtmdZlYSU9u0FtpNiS7DIjO7vRPq+rmZrTezVWb2jJk1e9uWzlpex/r9zSwj+hkXRdel/I6qJeY9h5jZK2a2Nrr+f6OZNueYWVXM53tHc6/VAbUd9XMxz6+jy2uVmU3shJpGxSyHFWa218xua9Km05aXmT1sZrvMbHXMtN5mttDM3os+92rhZ2+MtnnPzG5srs0xOecS8gGMAUYBi4DCmOljgZVABlAAbAKCzfz8k8CM6PADwH90cL2/BO5oYd5WILcTl92dwLeO0SYYXXbDgfToMh3bwXVdBISiw/cA9/i1vFrz+wNfAR6IDs8AnuiEz24AMDE63APvBu1N6zoHeL6z1qfWfi7ANOAFvHs4Tgbe7uT6gkAp3ok3viwv4GxgIrA6Ztr/ArdHh29vbr0HegObo8+9osO92vr+CbuF7pxb55zb0Mys6cAs51ytc24LUIR3I+sPmZkB5+HdsBrgz8AVHVVr9P0+DTzeUe/RAT68+bdzrg5ovPl3h3HOLXDONURHF+Pd/covrfn9p+OtO+CtS+dHP+sO45zb6Zx7Jzq8D1iHd8/eZDAd+IvzLAZ6mtmATnz/84FNzrnjPQO93Zxzr+LdEyJW7HrUUhZdDCx0zu12zn0ALASmtPX9EzbQj6K5m1Y3XeH7AHtiwqO5NvH0caDMOfdeC/MdsMDMlkVvlN0Zbo3+2/twC//itWY5dqSb8bbmmtMZy6s1v/9hNz8HGm9+3imiXTwTgLebmf1RM1tpZi+Y2UmdVNKxPhe/16kZtLxR5cfyatTPObczOlwK9GumTVyWXafeJLopM3sR6N/MrB845/7R2fU0p5U1XsvRt87Pcs6VmFlfYKGZrY/+Je+QuoDfA3fjfQHvxusOurk97xePuhqXl5n9AGgAHmvhZeK+vJKNmXUH/g7c5pzb22T2O3jdCvuj+0eeBUZ2QlkJ+7lE95FdDnyvmdl+La8jOOecmXXYseK+Brpz7oLj+LHW3LS6Eu/fvVB0y6q5NnGp0bybYl8FnHaU1yiJPu8ys2fw/t1v1xehtcvOzP4APN/MrNYsx7jXZWafAy4FznfRzsNmXiPuy6sZbbn5ebF14s3PzSwNL8wfc87Nbjo/NuCdc3PN7Hdmluuc69CLULXic+mQdaqVpgLvOOfKms7wa3nFKDOzAc65ndEuqF3NtCnB6+tvNBhv/2GbJGOXyxxgRvQIhAK8v7T/jm0QDYpX8G5YDd4NrDtqi/8CYL1zrri5mWaWbWY9Gofxdgyubq5tvDTpt7yyhfdrzc2/413XFOA7wOXOuZoW2nTW8krIm59H++gfAtY55+5toU3/xr58M5uE9z3u0D80rfxc5gCfjR7tMhmoiulq6Ggt/pfsx/JqInY9aimL5gMXmVmvaBfpRdFpbdMZe36P54EXRMVALVAGzI+Z9wO8IxQ2AFNjps8FBkaHh+MFfRHwFJDRQXU+Any5ybSBwNyYOlZGH2vwuh46etk9CrwLrIquTAOa1hUdn4Z3FMWmTqqrCK+fcEX08UDTujpzeTX3+wN34f3BAciMrjtF0XVpeCcso7PwuspWxSynacCXG9cz4NboslmJt3P5Y51QV7OfS5O6DLg/ujzfJebotA6uLRsvoHNipvmyvPD+qOwE6qP59Xm8/S4vAe8BLwK9o20LgT/G/OzN0XWtCLjpeN5fp/6LiKSIZOxyERGRZijQRURShAJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRfx/jrCeBk37KKQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVigyf9OU28g"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uu5pwjYVCi6"
      },
      "source": [
        "Q、シグモイド関数を微分したとき、入力値が0のとき最大値をとる。その値として正しい値はいくつか。\n",
        "\n",
        "A、0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWK5SMd_aG_S"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n63PHscaq-S"
      },
      "source": [
        "誤差逆伝播において、出力層から入力層に向かって誤差を伝播させる際、活性化関数の導関数を乗算していく必要がある。そのためネットワークの層が多くなるにつれて、入力層に伝わる誤差の値が非常に小さくなる。このことを(ア)という。特にシグモイド関数を活性化関数とした場合には、微分値が最大でも0.25となるため、この問題がより顕著に生じる。そこで提案されたのがReLUと呼ばれる活性化かんすうであり、(max(0,x))で表現される。ReLUは、微分値の最大が1であるため、シグモイド関数に比べて勾配消失が起こりにくい。このため、近年の層の深いニューラルネットワークではシグモイド関数に代わって頻繁に用いられている。\n",
        "\n",
        "(ア)・・・勾配消失"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRpQlutIbaTz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD8djP-sbcHd"
      },
      "source": [
        "# Section2:学習率最適化手法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_M1wIP3ecyc"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYuXZffjSx1"
      },
      "source": [
        "初期の学習率設定方法の指針\n",
        "\n",
        "・初期の学習率を大きく設定し、徐々に学習率を小さくしていく\n",
        "\n",
        "・パラメータごとに学習率を可変させる。\n",
        "\n",
        "これらを学習率最適化手法を利用して学習率を最適化させる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL3JCV4DenrZ"
      },
      "source": [
        "モメンタムのメリット\n",
        "\n",
        "・局所的最適解にならず。大域的最適解となる。\n",
        "\n",
        "・谷間についてから最も低い位置(最適値)に行くまでの時間が早い。\n",
        "\n",
        "AdaGradのメリット\n",
        "\n",
        "・勾配が緩やかな斜面に対して、最適解に近づける。\n",
        "\n",
        "・(課題)学習率が徐々に小さくなるので、鞍点問題を引き起こすことがあった。\n",
        "\n",
        "RMSPropのメリット\n",
        "\n",
        "・局所最適解にはならず、大域的最適解となる。\n",
        "\n",
        "・ハイパーパラメータの調整が必要な場合が少ない。\n",
        "\n",
        "Adamとは\n",
        "・モメンタムの過去の勾配の指数関数的減衰平均\n",
        "・RMSPropの、過去の勾配の2乗の指数関数的減衰平均\n",
        "これらをそれぞれ孕んだ最適化アルゴリズムである。\n",
        "\n",
        "Adamのメリット\n",
        "・モメンタム及びRMSPropのメリットを孕んだアルゴリズム。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klte1s7PnD8u"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE0aUCJLV7--"
      },
      "source": [
        "\"\"\"\n",
        "#AdaGrad\n",
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = {}\n",
        "            for key, val in params.items():\n",
        "                self.h[key] = np.zeros_like(val)\n",
        "            \n",
        "        for key in params.keys():\n",
        "            self.h[key] += grads[key] * grads[key]\n",
        "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApUDFj48tcVB"
      },
      "source": [
        "**考察結果**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc-TBCh35pfg"
      },
      "source": [
        "結局、どの最適化手法を使えばよいのか比較してみなければわからないという。現在でも新しい最適化手法がどんどん出てきていて、どの手法がベストとは言い切れないよう。実際、いろいろな記事を読んでも使っている最適化手法はバラバラである。 最適化手法のメリット、デメリットを知り、モデルに合った最適化手法を選ばねばならないことは確かなことである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4sVdgGl-aWY"
      },
      "source": [
        "**参考記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmxAIyCS-dPq"
      },
      "source": [
        "Q、ドロップアウトはニューラルネットワークの過剰適合を抑える手法として提案された。そのドロップアウトとはどういうものか記述せよ。\n",
        "\n",
        "A、訓練時、ユニットをランダムに消去しながらパラメータの最適化を行う。ユニットを消去する割合は定数として与える。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAaDGeNz_VRZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P44EFtZW_Zbe"
      },
      "source": [
        "# Section3:過学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAoJtz1z_hcv"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR6dOzWLymgK"
      },
      "source": [
        "過学習の原因は重みが大きい値をとることで、過学習が発生することがある。学習をさせていくと、重みにばらつきが発生する。重みが大きい値は、学習において重要な値であり、重みが大きいと過学習を起こす。\n",
        "\n",
        "過学習の解決策として、誤差に対して正則化を加算することで自由度を抑制し、重みを減らす。過学習がおこりそうな重みの大きさ以下で重みをコントロールし、かつ重みの大きさにばらつきを出す必要がある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swPL_pD7_iJG"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_vlWNTvdzu"
      },
      "source": [
        "#Dropout\n",
        "class Dropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_retio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_fig=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape)  > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ULgV31E4YZO"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijlHIxJc7GID"
      },
      "source": [
        "Q、L1正則化を表しているグラフは左右どちらか\n",
        "\n",
        "A、右のグラフ\n",
        "\n",
        "L1正則化はマンハッタン距離をる。特定のデータの重みを0にする事で、不要なデータを削除する。\n",
        "\n",
        "L2正則化はユークリッド距離を取る。データの大きさに応じて0に近づけて、滑らかなモデルとする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgt4pVsG8xN5"
      },
      "source": [
        "**演習問題**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSkmrxMe838s"
      },
      "source": [
        "深層学習において、過学習の抑制・汎化性能の向上のために正則化が用いられる。そのひとつに、L2ノルム正則化(Ridge,Weigh,Decay)がある。以下はL2ノルム正則化を適用した場合に、パラメータの更新を行うプログラムである。あるパラメータparamと正則化がないときにそのパラメータに伝播される誤差の勾配gradが与えられたとする。さて、最終的な勾配を計算する(え)にあてはまるものはどれか。だたしrateはL2ノルム正則化の係数を表すとする。\n",
        "\n",
        "def ridge(param, grad, rate):\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    param: target parameter\n",
        "    \n",
        "    grad: gradients to param\n",
        "    \n",
        "    rate: ridge coefficient\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    grad += rate * (あ)\n",
        "\n",
        " (あ)・・・param\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzW-1WmOxSNw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCbKa-zmxUdb"
      },
      "source": [
        "# Section4:畳み込みニューラルネットワークの概念"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZduSgj-UxgIY"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVT9BCTHxj2o"
      },
      "source": [
        "CNNでは次元間で繋がりのあるデータを扱える。1次元の単一チャネルでは音声データ、2次元ではフーリエ変換した音声データ(時刻、周波数、強度)、3次元ではCTスキャン画像(ｘ、y、ｚ、強度)。複数チャネルの1次元ではアニメのスケルトン、カラー画像、動画などである。\n",
        "\n",
        "畳み込み層では、画像の場合、縦、横、チャンネルの3次元のデータをそのまま学習し、次に伝えることができる。結論として、3次元の空間情報も学習できるような層が畳み込み層である。\n",
        "\n",
        "全結合層のデメリットは、画像の場合、縦、横、チャンネルの3次元のデータだが、1次元のデータとして処理される。結果として、RGBの各チャンネル間の関連性が、学習に反映されないということになる。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib_ZpVAbNoPu"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIGfclx63D2z"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def im2col(input_data, filter_h, filter_w, stride, pad, constant_values=0):\n",
        "    \"\"\"\n",
        "    input_data : (データ数, チャンネル数, 高さ, 幅)の4次元配列\n",
        "    filter_h : フィルタの高さ\n",
        "    filter_w : フィルタの幅\n",
        "    stride : ストライドサイズ\n",
        "    pad : パディングサイズ\n",
        "    constant_values : パディング処理で埋める際の値\n",
        "    \"\"\"\n",
        "\n",
        "    # 入力データのデータの数、 チャンネル数、 高さ、 幅を取得\n",
        "    N, C, H, W = input_data.shape\n",
        "\n",
        "    # 出力データの高さ(端数は切り捨てる)\n",
        "    out_h = (H + 2 * pad - filter_h) // stride + 1\n",
        "\n",
        "    # 出力データの幅(端数は切り捨てる)\n",
        "    out_w = (W + 2 * pad - filter_w) // stride + 1\n",
        "\n",
        "    # パディング\n",
        "    img = np.pad(input_data,\n",
        "                 (0, 0), (0, 0), (pad, pad), (pad, pad), \n",
        "                 \"constant\", \n",
        "                 constant_values=constant_values,)\n",
        "    # 配列の初期化\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    # フィルタ内のある1要素に対応する画像中の画素を取り出してcolに代入\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride * out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride * out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    # 軸を入れ替えて、2次元配列(行列)に変換する\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
        "\n",
        "    return col\n",
        "\n",
        "def maxpooling_forward(x, pad, stride, pool_h, pool_w):\n",
        "    \"\"\"\n",
        "    x : 入力データ, 配列形状 = (データ数, チャンネル数, 高さ, 幅)\n",
        "    pad : パディングサイズ\n",
        "    stride : ストライドサイズ\n",
        "    pool_h : プーリング領域の縦\n",
        "    pool_w : プーリング領域の横\n",
        "    \"\"\"\n",
        "\n",
        "    N, C, H, W = x.shape\n",
        "\n",
        "    # 出力の高さ(端数は切り捨てる)\n",
        "    out_h = (H + 2 * pad - pool_h) // stride + 1\n",
        "\n",
        "    # 出力の幅(端数は切り捨てる)\n",
        "    out_w = (W + 2 * pad - pool_w) // stride + 1\n",
        "\n",
        "    # 2次元配列に変換する\n",
        "    col = im2col(x, pool_h, pool_w, stride, pad)\n",
        "\n",
        "    # チャンネル方向のデータが横に並んでいるので、縦に並び替える\n",
        "    col = col.reshape(-1, pool_h * pool_w)\n",
        "\n",
        "    # 最大値のインデックス(逆伝播時に使用)を求める\n",
        "    out_idx = np.argmax(col, axis=1)\n",
        "\n",
        "    # 最大値を求める\n",
        "    out = np.max(col, axis=1)\n",
        "\n",
        "    # 画像形式に戻して、チャンネルの軸を2番めに移動させる\n",
        "    out = out,reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "\n",
        "    return out_idx, out\n",
        "\n",
        "def convolution_forward(x, W, b, pad, stride):\n",
        "    \"\"\"\n",
        "    x : 入力データ, 配列形状 = (データ数, チャンネル数, 高さ, 幅)\n",
        "    W : フィルタ, 配列形状 = (出力チャンネル数, 入力チャンネル数, 高さ, 幅)\n",
        "    b : バイアス\n",
        "    pad : パディングサイズ\n",
        "    stride : ストライドサイズ\n",
        "    \"\"\"\n",
        "    FN, C, FH, FW = W.shape\n",
        "    N, C, H, W = x.shape\n",
        "\n",
        "    # 出力の高さ(端数は切り捨てる)\n",
        "    out_h = (H + 2 * pad - FN) // stride + 1\n",
        "\n",
        "    # 出力の幅(端数は切り捨てる)\n",
        "    out_w = (W + 2 * pad - FW) // stride + 1\n",
        "\n",
        "    # 畳み込み演算を効率に行えるようにするため、入力ｘを行列colに変換する\n",
        "    col = im2col(x, FH, FW, stride, pad)\n",
        "\n",
        "    # フィルタを2次元配列に変換する\n",
        "    col_W = W.reshape(FN, -1).T\n",
        "\n",
        "    # 行列の積を計算し。バイアスを足す\n",
        "    out = np.dot(col, col_W) + b\n",
        "    \n",
        "    # 画像形式に戻して、チャンネルの軸を2番めに移動させる\n",
        "    out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKCbHpXhdeMT"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqHJ-9Q_d24a"
      },
      "source": [
        "Q、サイズ6＊6の入力画像を、サイズ2＊2のフィルタで畳み込みを行ったときの出力画像のサイズを求めよ。なお、ストライドとパディングは1とする。\n",
        "\n",
        "公式\n",
        "\n",
        "OH 出力画像の高さ = (画像の高さ ＋ 2 ＊ パディングの高さ − フィルターの高さ) / ストライド + 1\n",
        "\n",
        "OW 出力画像の幅 = (画像の幅 ＋ 2 ＊ パディングの幅 − フィルターの幅) / ストライド + 1\n",
        "\n",
        "= {(6 + 2) * 1 - 2 / 1} + 1\n",
        "\n",
        "= 7\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmPr0P_PhmfT"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJJzMaM5hrsF"
      },
      "source": [
        "Q、高速な物体検出モデルとしては、入力画像を複数の少領域に分割し、各少領域ごとにクラス分類とバウンディングボックスの位置や大きさなどの回帰を行う(ア)や、大きさの異なる複数の特徴マップを使ってクラス分類やバウンディングボックス回帰を行う(イ)がある\n",
        "\n",
        "(ア)・・・YOLO\n",
        "\n",
        "(イ)・・・SSD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KTyZVF8ju2F"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Aiog-ijxJX"
      },
      "source": [
        "# Section5:最新のCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFDoaZOBj7H6"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oikq0qGlkTN9"
      },
      "source": [
        "初期頃のニューラルネットワークであるAlexNetモデルの構造は、5層の畳み込み層及びプーリング層など、それに続く3層の全結合層から構成されている。過学習を防ぐ施策として、サイズ4096の全結合層の出力にドロップアウトを使用している。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDbgPGUGElMT"
      },
      "source": [
        "**サマリー**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwpZEBaeErRi"
      },
      "source": [
        "LeNetからAlexNetで変わったこと\n",
        "\n",
        "・活性化関数にReLUを用いる。\n",
        "\n",
        "・LRN(Local Response Normalization) という局所的正規化を行う層を用いる\n",
        "\n",
        "・Dropoutを使用する。\n",
        "\n",
        "環境やコンピュータ技術の進展によってCNNのネットワーク構造も変化していく。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZpWZS-CHKGL"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ48Dm8KD47z"
      },
      "source": [
        "画像認識分野においては、畳込みニューラルネットワーク(Convolutional Neural Network, CNN)が非常に顕著な成果を出している。畳み込み層とプーリング層を交互に繰り返すのが、CNNの基本的な構造である。(ア)は入力の小さな移動に対して不変な表現を作るのに役立つ。移動に対する不変性とは、入力を水平または垂直方向に多少変化させても出力にはほとんど変化がないという性質である。これが、手書き文字認識といった画像中の厳密な位置ではなく、画像中にどのような文字があるのかに関心がある場合に有用となる。\n",
        "\n",
        "(ア)・・・畳み込み層とプーリング層\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEYWJB3rF9Az"
      },
      "source": [
        "**関連記事** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgZv4ivvGAJS"
      },
      "source": [
        "(あ)とは、畳み込みの対象となる領域をベクトル化し、それを並べた行列を作成する処理を指す。これにより、本来ループ処理によって実装される畳み込みをNumpyの行列積によって実装することが可能となる。\n",
        "\n",
        "(あ)・・・im2col (image to columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRObYe6BIgev"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWlntzzmbl1P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}